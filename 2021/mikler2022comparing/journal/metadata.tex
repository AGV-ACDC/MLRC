% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/gahaalt/reproducing-comparing-rewinding-and-finetuning}
\def \codeDOI{00.0000/zenodo.0000000}
\def \codeSWH{swh:1:dir:886a4c9a0bdecdbf65f2cab3ae7404a6796bc451}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{}
\def \dateACCEPTED{}
\def \datePUBLISHED{}
\def \articleTITLE{[Re] Reproducibility Study: Comparing Rewinding and Fine-tuning in Neural Network Pruning}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2021}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2022}
\def \reviewURL{https://openreview.net/forum?id=HxWEL2zQ3AK}
\def \articleABSTRACT{We are reproducing Comparing Rewinding and Fine-tuning in Neural Networks, by Renda. In this work the authors compare three different approaches to retraining neural networks after pruning: 1) fine-tuning, 2) rewinding weights as in Frankle and 3) a new, original method involving learning rate rewinding, building upon Frankle. We reproduce the results of all three approaches, but we focus on verifying their approach, learning rate rewinding, since it is newly proposed and is described as a universal alternative to other methods.
We used CIFAR10 for most reproductions along with additional experiments on the larger CIFAR100, which extends the results originally provided by the authors. We have also extended the list of tested network architectures to include Wide ResNets. The new experiments led us to discover the limitations of learning rate rewinding which can worsen pruning results on large architectures.}
\def \replicationCITE{Renda, Alex and Frankle, Jonathan and Carbin, Michael. Comparing Rewinding and Fine-tuning in Neural Network Pruning (ICLR 2020).}
\def \replicationBIB{renda2020}
\def \replicationURL{https://arxiv.org/abs/2003.02389}
\def \replicationDOI{https://doi.org/10.48550/arXiv.2003.02389}
\def \contactNAME{Szymon Mikler}
\def \contactEMAIL{sjmikler@gmail.com}
\def \articleKEYWORDS{rescience c, machine learning, deep learning, python, tensorflow, computer vision, pruning}
\def \journalNAME{ReScience C}
\def \journalVOLUME{9}
\def \journalISSUE{1}
\def \articleNUMBER{}
\def \articleDOI{10.0000/zenodo.0000000}
\def \authorsFULL{Szymon Mikler}
\def \authorsABBRV{S. Mikler}
\def \authorsSHORT{Mikler}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0000-0002-7549-571X}]{Szymon Mikler}
\affil[1]{University of Wroclaw, Poland}
