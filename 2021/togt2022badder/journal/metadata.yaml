# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[Â¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[Re] Badder Seeds: Reproducing the Evaluation of Lexical Methods for Bias Measurement"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Jille van der Togt
    orcid: 0000-0002-6385-6231
    email: jille.vandertogt@student.uva.nl
    affiliations: 1,2

  - name: Lea Tiyavorabun
    orcid: 0000-0001-9912-4641
    email: lea.tiyavorabun@student.uva.nl
    affiliations: 1,2

  - name: Matteo Rosati
    orcid: 0000-0002-3963-6845
    email: matteo.rosati@student.uva.nl
    affiliations: 1,2

  - name: Giulio Starace
    orcid: 0000-0001-5284-4238
    email: giulio.starace@gmail.com
    affiliations: 1,2,* # * is for contact author

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code: 1
    name: University of Amsterdam
    address: Amsterdam, the Netherlands
  - code: 2
    name: Equal contributions

# List of keywords (adding the programming language might be a good idea)
keywords:
  rescience c, machine learning, deep learning, python, pytorch, nlp, bias,
  seeds

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/thesofakillers/badder-seeds
  - swh: swh:1:dir:13ff45fd249e765a221d49f701c32d45b64ee675
  - doi: 10.5281/zenodo.6480966

# Information about the original article that has been replicated
replication:
  - cite:
      "Maria Antoniak, David Mimno. Bad Seeds: Evaluating Lexical Methods for
      Bias Measurement (ACL 2021)."
  - bib: antoniak-mimno-2021-bad
  - url: https://aclanthology.org/2021.acl-long.148/
  - doi: 10.18653/v1/2021.acl-long.148

# Don't forget to surround abstract with double quotes
abstract:
  "Combating bias in NLP requires bias measurement. Bias measurement is almost
  always achieved by using lexicons of seed terms, i.e. sets of words specifying
  stereotypes or dimensions of interest. This reproducibility study focuses on
  the original authors' main claim that the rationale for the construction of
  these lexicons needs thorough checking before usage, as the seeds used for
  bias measurement can themselves exhibit biases. The study aims to evaluate the
  reproducibility of the quantitative and qualitative results presented in the
  paper and the conclusions drawn thereof. We reproduce most of the results
  supporting the original authors' general claim: seed sets often suffer from
  biases that affect their performance as a baseline for bias metrics.
  Generally, our results mirror the original paper's. They are slightly
  different on select occasions, but not in ways that undermine the paper's
  general intent to show the fragility of seed sets."

# Bibliography file (yours)
bibliography: bibliography.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2021

# Coding language (main one only if several)
language: Python

# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=HcIxA3Mm2CF

contributors:
  - name: Koustuv Sinha
    orcid:
    role: editor
  - name: Anonymous Reviewers
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer

# This information will be provided by the editor
dates:
  - received:  February 4, 2022
  - accepted:  April 11, 2022
  - published:  May 18, 2022

# This information will be provided by the editor
article:
  - number: 34
  - doi: 10.0000/zenodo.0000000 # DOI from Zenodo
  - url: https://zenodo.org/record/0000000/files/article.pdf # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name: "ReScience C"
  - issn: 2430-3658
  - volume: 8
  - issue: 2
