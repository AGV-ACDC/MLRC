# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[¬Re] Reproducibility Study of 'Exacerbating Algorithmic Bias through Fairness Attacks' "

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Isa-Ali Kirca
    orcid: 0000-0001-7903-1341
    email: isaali.kirca@hotmail.com
    affiliations: 1,2

  - name: Daniël Hamerslag
    orcid: 0000-0002-9830-7240
    email: d.c.hamerslag@gmail.com
    affiliations: 1,2,*

  - name: Afra Baas
    orcid: 0000-0003-4276-6429
    email: afra1baas@gmail.com
    affiliations: 1,2

  - name: Juno Prent
    orcid: 0000-0003-2958-5885
    email: junoprent@live.nl
    affiliations: 1,2


# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations: 
  - code:  1  
    name:  Equal contributions
  - code:  2
    name:  Faculty of Science, University of Amsterdam
    address: Science Park 904, 1098 XH Amsterdam, the Netherlands


# List of keywords (adding the programming language might be a good idea)
keywords:  rescience c, machine learning, deep learning, python

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/DCHamerslag/FACT
  - doi: 10.5281/zenodo.6491095
  - swh: swh:1:dir:25564a437957494e991b5205e262159e75d84d59;


# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "Ninareh Mehrabi, Muhammad Naveed, Fred Morstatter, Aram Galstyan. Exacerbating Algorithmic Bias through Fairness Attacks."
 - bib:  Mehrabi2021ExacerbatingAB
 - url:  https://arxiv.org/pdf/2012.08723.pdf
 - doi:  https://doi.org/10.48550/arXiv.2012.08723

# Don't forget to surround abstract with double quotes
abstract: "The goal of this paper is to assess the reproducibility of experiments and results in the paper 
'Exacerbating Algorithmic Bias through Fairness Attacks' by Mehrabi et al. (2020), 
from which the following claims are evaluated:
- Claim 1: The anchoring attacks reduce the fairness of an ML model trained on 
the three data sets German Credit, COMPAS and Drug consumption.
- Claim 2: The influence attack reduces the fairness of an ML model trained on 
the three data sets German Credit, COMPAS and Drug consumption.
The code the authors published was utilized alongside their paper as a resource to understand 
the methodology of their experiments, which was only briefly touched upon in the original paper. 
Our contribution is to extrapolate the original method using the provided code 
and to use this to recreate the experiments, successfully obtaining similar results as the paper 
and supporting their claims.
Our results followed similar patterns as those of the authors, which backs up their claims regarding the attacks. 
However, our results did slightly deviate from their results, meaning the original paper has 
some reproducibility issues in the context of our experimental setup.
It was difficult to understand the experiments from the paper. 
In our specific setting it was not possible to obtain similar results following only the 
methodology of their paper. Recreating the data sets required several assumptions. 
Reorganizing the code was a challenge in and of itself, owing to a lack of documentation within the original code.
We had no direct contact with the authors. However, other research teams working on 
reproducing the same work provided us with a digital environment file supplied to them by the authors."

# Bibliography file (yours)
bibliography: bibliography.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2021

# Coding language (main one only if several)
language: Python


# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=rKbgh3fXnRK

contributors:
  - name: Koustuv Sinha
    orcid:
    role: editor
  - name: Anonymous Reviewers
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer


# This information will be provided by the editor
dates:
  - received:  February 4, 2022
  - accepted:  April 11, 2022
  - published: May 15, 2022


# This information will be provided by the editor
article:
  - number: 0 # Article number will be automatically assigned during publication
  - doi: 10.0000/zenodo.0000000   # DOI from Zenodo
  - url: https://zenodo.org/record/0000000/files/article.pdf   # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name:   "ReScience C"
  - issn:   2430-3658
  - volume: 9
  - issue:  1
