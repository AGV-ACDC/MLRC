% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/kayatb/reproduce_SCOUTER}
\def \codeDOI{}
\def \codeSWH{swh:1:dir:a294d795e2f9e00a93e9955b70c86a28b1c310d0}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{Koustuv Sinha}
\def \editorORCID{}
\def \reviewerINAME{Anonymous Reviewers}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{04 February 2022}
\def \dateACCEPTED{11 April 2022}
\def \datePUBLISHED{15 May 2022}
\def \articleTITLE{[Re] Reproducibility Study - SCOUTER: Slot Attention-based Classifier for Explainable Image Recognition}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2021}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2022}
\def \reviewURL{https://openreview.net/forum?id=HZNlq3fmhRF}
\def \articleABSTRACT{Scope of Reproducibility. We aim to replicate the main findings of the paper 	extit{SCOUTER: Slot Attention-based Classifier for Explainable Image Recognition} by Li et al. in order to verify the main claims they make: 1) The explanations generated by SCOUTER outperform those by other explanation methods in several explanation evaluation metrics. 2) SCOUTER achieves similar classification accuracy as a fully connected model. 3) SCOUTER achieves higher confusion matrix metrics than a fully connected model on a binary classification problem.
Methodology. The authors provided code for training the models. We implemented the explanation evaluation metrics and confusion matrix metrics ourselves. We used the same hyperparameters as the original work, in case the hyperparameter was reported. We trained all models from scratch on various datasets and evaluated the explanations generated by these models with all reported metrics. We compared the accuracy scores between different models on several datasets. Finally, we calculated an assortment of confusion matrix metrics on models trained on a binary dataset.
Results. We were only able to reproduce 22.2 percent of the explanation evaluation metrics and could thus not find conclusive support for claim 1. We could only verify claim 2 for one of the datasets and in total could reproduce 55.5 percent of the original scores. We could reproduce all scores regarding claim 3, but the claim is still not justified, as the scores between the fully connected and SCOUTER models lie very close to one another.
What was easy. The paper was well written, so understanding the SCOUTER architecture was straightforward. The code for training a model was available and together with the examples the authors provide, this was achievable with relative ease. A checkpoint system is implemented, so training a model can be split into multiple runs. All used datasets are available and straightforward to obtain.
What was difficult. The original code did not contain any documentation, which made it difficult to navigate. No code for calculating the metrics was provided and this had to be implemented from scratch. During the training of the models, memory allocation issues occurred. Training and evaluating on a large dataset took a considerable amount of time.
Communication with the original authors. We sent the authors an e-mail to request either the missing code or more details on how the metrics were implemented, but unfortunately we did not receive a reply.}
\def \replicationCITE{Liangzhi Li, Bowen Wang, Manisha Verma, Yuta Nakashima, Ryo Kawasaki, and Hajime Nagahara. SCOUTER: slot attention-based classifier for explainable image recognition. (ICCV 2021)}
\def \replicationBIB{li2021scouter}
\def \replicationURL{https://arxiv.org/abs/2009.06138}
\def \replicationDOI{10.48550/arXiv.2009.06138}
\def \contactNAME{Maarten Burger}
\def \contactEMAIL{maarten.l.burger@gmail.com}
\def \articleKEYWORDS{rescience c, machine learning, deep learning, SCOUTER, XAI, Explainable, AI, Interpretable, Reproducibility, Attention, Self-attention, Computer Vision, python, pytorch}
\def \journalNAME{ReScience C}
\def \journalVOLUME{9}
\def \journalISSUE{1}
\def \articleNUMBER{}
\def \articleDOI{10.0000/zenodo.0000000}
\def \authorsFULL{Maarten Burger et al.}
\def \authorsABBRV{M. Burger et al.}
\def \authorsSHORT{Burger et al.}
\title{\articleTITLE}
\date{}
\author[1,2,\orcid{0000-0002-0866-2637}]{Maarten Burger}
\author[1,2,\orcid{0000-0003-4630-4897}]{Kaya ter Burg}
\author[1,\orcid{0000-0000-000-001}]{Sam Titarsolej}
\author[1,\orcid{0000-0000-000-001}]{Selina Jasmin Khan}
\affil[1]{University of Amsterdam, Amsterdam, the Netherlands}
\affil[2]{Equal contributions,  }
