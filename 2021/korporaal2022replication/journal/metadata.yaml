# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[Â¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[Re] Replication study of 'Explaining in Style: Training a GAN to explain a classifier in StyleSpace'"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Evaline Bosch
    orcid: 0000-0001-7913-2812
    email: evaline00@live.com
    affiliations: 1,

  - name: Rutger Ettes
    orcid: 0000-0003-2721-6162
    email: rutgerettes@gmail.com
    affiliations: 1,

  - name: Daan Korporaal
    orcid: 0000-0002-8899-4374
    email: daankorporaal@gmail.com
    affiliations: 1,*       # * is for contact author

  - name: Gijs van Meer
    orcid: 0000-0002-1215-4221
    email: gijsvanmeer@gmail.com
    affiliations: 1,

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    University of Amsterdam
    address: Amsterdam, NL


# List of keywords (adding the programming language might be a good idea)
keywords:  rescience c, machine learning, deep learning, python, pytorch, AI, GANs, SyleSpace, reconstruction

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/Gijsvanmeer/FACTinAI
  - doi: 10.5281/zenodo.6508302
  - swh: swh:1:dir:1d0dbddb7bc7060aee89621b45cea15325dca1b1

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "Lang, Oran and Gandelsman, Yossi and Yarom, Michal and Wald, Yoav and Elidan, Gal and Hassidim, Avinatan and Freeman, William T. and Isola, Phillip and Globerson, Amir and Irani, Michal and Mosseri, Inbar. Explaining in Style: Training a GAN to explain a classifier in StyleSpace."
 - bib:  explaining_in_style
 - url:  https://arxiv.org/pdf/2104.13369.pdf
 - doi:  https://doi.org/10.48550/arXiv.2104.13369 # Regular digital object identifier

# Don't forget to surround abstract with double quotes
abstract: "Scope of Reproducibility
In this report claims made in the paper 'Explaining in Style: Training a GAN to explain a classifier in StyleSpace' will be tested. This paper claims that by creating a generative model based on pre-trained classifier it is possible to discover and visually explain the underlying attributes that influence the classifier output which can lead to counterfactual explanations. From this it can be deduced what classifiers are learning.

Methodology
To reproduce the StylEx architecture that has been proposed an already existing implementation of the  styleGAN2 model is modified. To implement the AttFind algorithm found in the paper the original TensorFlow code has been converted in to PyTorch code. Furthermore due to the restraint of only having access to one GPU the image resolution has been down scaled to 64x64 pixels such that computation time will not be to extensive.

Results
A model is created for both dog-cat and age classification. The models performed worse than stated than the pretrained models, most likely due to some issues with the StylEx style space, as AttFind performed well on the StyleGAN2 model. Due to the limitations in the adaptation it is not possible to definitively state whether the claims are true or false.

What was easy
Pretrained models and the AttFind algorithm were available for execution. It was therefore possible to quickly obtain some results given in the original paper by the authors. It gave a good baseline of what to expect should everything run correctly.

What was difficult
No training code or information on the training procedure was available publicly, meaning it had to be created from scratch. Although the AttFind algorithm was available, it was in TensorFlow and not PyTorch therefore this needed to be converted. Implementing and training everything ended up taking a lot of time and resources, causing a hyperparameter search and further research not to be possible.

Communication with original authors
We have had contact with the original authors and many of our questions about their paper were answered. Response time was fast as well, usually taking no longer than 40 hours."

# Bibliography file (yours)
bibliography: sources.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2021

# Coding language (main one only if several)
language: Python


# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=BtIz0nz7hRY

contributors:
  - name: 
    orcid:
    role: editor
  - name: 
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer


# This information will be provided by the editor
dates:
  - received:  
  - accepted:  
  - published: 


# This information will be provided by the editor
article:
  - number:  # Article number will be automatically assigned during publication
  - doi:    # DOI from Zenodo
  - url:    # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name:   
  - issn:   
  - volume: 
  - issue:  
