# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[Â¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[Re] Replication Study of DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Velizar Shulev
    orcid: 0000-0002-6284-866X
    email: velizar.shulev@student.uva.nl
    affiliations: 1,*

  - name: Paul Verhagen
    orcid: 0000-0002-3192-5001
    email: paul.verhagen@student.uva.nl
    affiliations: 1

  - name: Shuai Wang
    orcid: 0000-0002-1595-3619
    email: shuai.wang@student.uva.nl
    affiliations: 1

  - name: Jennifer Zhuge
    orcid: 0000-0001-9097-5239
    email: jenn.zhuge@student.uva.nl
    affiliations: 1

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    Universiteit van Amsterdam
    address: Amsterdam, the Netherlands


# List of keywords (adding the programming language might be a good idea)
keywords:  rescience c, machine learning, deep learning, python, pytorch, reproducibility, causal graphs, debiasing

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/ShuaiWang97/UvA_FACT2022
  - doi: 10.5281/zenodo.6515893
  - swh: swh:1:dir:78ac8ec89fd95397fd635e8d9e885e1d5ac6c039

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "Boris van Breugel, Trent Kyono, Jeroen Berrevoets, Mihaela van der Schaar, 2021)."
 - bib:  wang2022replication
 - url:  https://arxiv.org/pdf/2110.12884.pdf
 - doi:  https://doi.org/10.48550/arXiv.2110.12884

# Don't forget to surround abstract with double quotes
abstract: "We attempt to reproduce the results of \"DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks\". The goal of the original paper is to create a model that takes as input a biased dataset and outputs a debiased synthetic dataset that can be used to train downstream models to make unbiased predictions both on synthetic and real data. We built upon the (incomplete) code provided by the authors to repeat the first experiment which involves removing existing bias from real data, and the second experiment where synthetically injected bias is added to real data and then removed. Overall, we find that the results are reproducible but difficult to interpret and compare because reproducing the experiments required rewriting or adding large sections of code. We reproduced most of the data utility results reported in the first experiment for the Adult dataset. Though the fairness metrics generally match the original paper, they are numerically not comparable in absolute or relative terms. For the second experiment, we were unsuccessful in reproducing results. However, we note that we made considerable changes to the experimental setup, which may make it difficult to perform a direct comparison. There are several possible interpretations of the paper on methodological and conceptual levels that made it difficult to be confident in the reproduction. Although we were not able to reproduce the results in full, we believe methods like DECAF have great potential for future work."

# Bibliography file (yours)
bibliography: bibliography.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2021

# Coding language (main one only if several)
language: Python


# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=SVx46hzmhRK

contributors:
  - name:
    orcid:
    role: editor
  - name:
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer


# This information will be provided by the editor
dates:
  - received:  February 4, 2022
  - accepted:  April 11, 2022
  - published:  May 18, 2022


# This information will be provided by the editor
article:
  - number: 42
  - doi: 10.0000/zenodo.0000000   # DOI from Zenodo
  - url: https://zenodo.org/record/0000000/files/article.pdf   # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name:   "ReScience C"
  - issn:   2430-3658
  - volume: 8
  - issue: 2
