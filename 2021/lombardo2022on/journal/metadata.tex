% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/imandrealombardo/FACT-AI}
\def \codeDOI{}
\def \codeSWH{swh:1:dir:b775237e47e9de16827cb9cae83423d090faa4f8}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{Koustuv Sinha,\\ Sharath Chandra Raparthy}
\def \editorORCID{}
\def \reviewerINAME{Anonymous Reviewers}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{04 February 2022}
\def \dateACCEPTED{11 April 2022}
\def \datePUBLISHED{23 May 2022}
\def \articleTITLE{[Re] Exacerbating Algorithmic Bias through Fairness Attacks}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2021}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2022}
\def \reviewURL{https://openreview.net/forum?id=H4lzChGmhCK}
\def \articleABSTRACT{The presented study evaluates ''Exacerbating Algorithmic Bias through Fairness Attacks'' by Mehrabi et al. (2021) within the scope of the ML Reproducibility Challenge 2021. We find it not possible to reproduce the original results from sole use of the paper, and difficult even in possession of the provided codebase. Yet, we managed to obtain similar findings that supported three out of the five main claims of the publication, albeit using partial re-implementations and numerous assumptions. On top of the reproducibility study, we also extend the work of the authors by implementing a different stopping method, which changes the effectiveness of the proposed attacks.}
\def \replicationCITE{Mehrabi, N., Naveed, M., Morstatter, F., & Galstyan, A. (2021). Exacerbating Algorithmic Bias through Fairness Attacks. Proceedings of the AAAI Conference on Artificial Intelligence, 35(10), 8930-8938.}
\def \replicationBIB{originalpaper}
\def \replicationURL{https://arxiv.org/pdf/2012.08723.pdf}
\def \replicationDOI{10.48550/arXiv.2012.08723}
\def \contactNAME{Matteo Tafuro}
\def \contactEMAIL{matteo.tafuro@student.uva.nl}
\def \articleKEYWORDS{rescience c, rescience x, reproducibility, machine learning, deep learning, fairness, python, tensorflow, adversarial attack, fairness attack, algorithmic bias, influence attack on fairness, anchoring attack}
\def \journalNAME{ReScience C}
\def \journalVOLUME{8}
\def \journalISSUE{2}
\def \articleNUMBER{22}
\def \articleDOI{10.5281/zenodo.6574669}
\def \authorsFULL{Matteo Tafuro et al.}
\def \authorsABBRV{M. Tafuro et al.}
\def \authorsSHORT{Tafuro et al.}
\title{\articleTITLE}
\date{}
\author[1,2,\orcid{0000-0002-6167-2156}]{Matteo Tafuro}
\author[1,2,\orcid{0000-0002-0478-2527}]{Andrea Lombardo}
\author[1,2,\orcid{0000-0002-0328-7372}]{Tin Hadži Veljković}
\author[1,2,\orcid{0000-0002-7701-8319}]{Lasse Becker-Czarnetzki}
\affil[1]{M.Sc. Artificial Intelligence, University of Amsterdam, 1012 WX Amsterdam, The Netherlands}
\affil[2]{Equal contributions}
