\newpage
\appendix
\section*{Appendix}

\section{Table of issues}
\label{app:issues}

\resizebox{\columnwidth}{!}{\begin{tabular}{p{8cm} p{8cm}}
 \toprule
 \textbf{Issue}& \textbf{Our contribution}\\
 \midrule
 Running the code in the given environment results in conflicts   & Code modernized and made compatible with the latest version of every dependency\\
 \midrule[0.05mm]
 The code is generally complex and hard to understand due to insufficient comments and documentation as well as leftover code&Trimmed down the code to the essential, included option to choose any of the available models and the corresponding parameters. Added comprehensive documentation to make the code more interpretable\\
 \midrule[0.05mm]
 It appears that the pre-processing pipeline of the given datasets is not specified &Made the scripts we used to pre-process each dataset available as well as a detailed description\\
 \midrule[0.05mm]
 It appears that the position (i.e. index) of the sensitive feature for the COMPAS and Drug Consumption datasets is not indicated, posing a challenge to reproduce the authors' results&Moved the sensitive feature (i.e. gender) of every dataset to the 0th index, which is taken as default by the main function\\
 \midrule[0.05mm]
 The advantaged and disadvantaged groups for the sensitive attribute (gender) has not be specified for any attack&Assumed from the codebase that the authors did this automatically and inferred it from the dataset (the advantaged group is chosen as the group with a higher ratio of datapoints with the positive label (y=1), regardless of the actual class label it corresponds to) to be specified for all attacks\\
 \midrule[0.05mm]
 The code does not provide an option to run baseline methods used in the paper, nor does it include the hyperparameter $\lambda$ &Included option to run baseline methods (Koh attack, Solans attack) and to include $\lambda$ in IAF attack\\
 \midrule[0.05mm]
 The code implements a deterministic point sampling in the anchoring attacks (RAA, NRAA) due to the same seed being reset in every attack iteration. Thus the sampling yields the same point every iteration not properly applying the randomness&Fixed the issue so that randomness takes effect\\
 \midrule[0.05mm]
 The code makes use of a faulty EOD metric calculation&Re-implemented the EOD metric calculation to fix the issue\\
 \midrule[0.05mm]
 The paper specifies the feasible set computation to be done on the union of the clean dataset and the initial poisoned points. The original code however does this on the clean data only when using the running commands given by the authors&Implemented the feasible set as specified in the paper\\
 \midrule[0.05mm]
 It appears that the model used for the given classification task is not specified&Assumed they used a Support Vector Machine (SVM) trained with a smooth hinge loss and L2 regularization\\
 \midrule[0.05mm]
 The optimization algorithm is not indicated&Assumed it to be Newtons Conjugate Gradient (Newton-CG) method, as suggested by the codebase\\
 \midrule[0.05mm]
 It is unclear how the best performing model was selected&Saved best performing model on the test set according to the chosen stopping metric\\
 \bottomrule
\label{tab:inconsistencies}

\end{tabular}}


\section{Additional figures}
Here we collect additional figures that support the results discussed above.

\subsection{Effect of $\lambda$ on the different metrics}
\label{app:lambda}

Figure \ref{fig:2-stop-accuracy} shows the influence of $\lambda$ on the different metrics when \textit{accuracy} is used as the stopping criteria. The experiment is repeated using \textit{average fairness} as the stopping metric, and the results are collected in Figure \ref{fig:2-stop-fairness}. These results support \hyperlink{claim-1}{\textit{Claim 1}} of Section \ref{sec:claims}, effectively proving it.

\subsection{Comparative study between the proposed attacks and the baselines}\label{app:comparative}
We report the results of the experiment designed to support \hyperlink{claim-2}{\textit{Claims 2-5}} of Section \ref{sec:claims}. We perform each attack (IAF, NRAA, RAA, Koh, Solans) on each dataset (German, Compas, Drug), fixing $\lambda = 1$ and gradually increasing $\epsilon$ from 0.0 to 1.0, with steps of 0.1. We repeat this procedure for each stopping metric (average fairness and accuracy). The results are respectively collected in Figures \ref{fig:2-stop-fairness} and \ref{fig:3-stop-accuracy}.

\subsection{Figures of the original paper}\label{app:orig-figs}
For the sake of self-containedness of this reproducibility study, we report the two main figures of the original paper. Figures \ref{fig:orig-fig2} and \ref{fig:orig-fig3} correspond -- respectively -- to Figures 2 and 3 of "Exacerbating Algorithmic Bias through Fairness Attacks".

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/Figure_2_stopping_accuracy.pdf}
    \caption{Results obtained for different attacks with regards to accuracy (test error) and fairness (SPD and EOD) measures on German Credit, COMPAS, and Drug Consumption databases with different $\epsilon$ values and with \textit{accuracy} as the stopping method.}
    \label{fig:2-stop-accuracy}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/Figure_2_stopping_fairness.pdf}
    \caption{Results obtained for different attacks with regards to accuracy (test error) and fairness (SPD and EOD) measures on German Credit, COMPAS, and Drug Consumption databases with different $\epsilon$ values and with \textit{average fairness} as the stopping method.}
    \label{fig:2-stop-fairness}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/Figure_3_stopping_accuracy.pdf}
    \caption{Accuracy (test error) and fairness (SPD and EOD) measures obtained after the IAF attack the on German Credit, COMPAS, and Drug Consumption databases for different $\epsilon$ and increasing $\lambda$ values,  with \textit{accuracy} as the stopping method.}
    \label{fig:3-stop-accuracy}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/Figure_3_stopping_fairness.pdf}
    \caption{Accuracy (test error) and fairness (SPD and EOD) measures obtained after the IAF attack the on German Credit, COMPAS, and Drug Consumption databases for different $\epsilon$ and increasing $\lambda$ values, with \textit{average fairness} as the stopping method.}
    \label{fig:3-stop-fairness}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/original_figure2.pdf}
    \caption{Results of the original paper obtained for different attacks with regards to different fairness (SPD and EOD) and accuracy (test error) measures on three different datasets (German Credit, COMPAS, and Drug Consumption) with different $\epsilon$ values. Retrieved from \citep{originalpaper}.}
    \label{fig:orig-fig2}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/original_figure3.pdf}
    \caption{Results of the original paper obtained for different $\lambda$ values for the IAF attack with regards to different fairness (SPD and EOD) and accuracy (test error) measures on three different datasets (German Credit, COMPAS, and Drug Consumption) with different $\epsilon$. Retrieved from \citep{originalpaper}.}
    \label{fig:orig-fig3}
\end{figure}


