# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[Â¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[Re] Value Alignment Verification"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Siba Smarak Panigrahi
    orcid: 0000-0003-2525-988X
    email: sibasmarak.p@gmail.com
    affiliations: 1,2,*

  - name: Sohan Patnaik
    orcid: 0000-0002-4181-4161
    email: sohanpatnaik106@gmail.com
    affiliations: 1,2      # * is for contact author

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    Equal Contributions
    address: ""
    
  - code:    2
    name:    Indian Institute of Technology Kharagpur
    address: India



# List of keywords (adding the programming language might be a good idea)
keywords:  rescience c, value alignment verification, reinforcement learning, machine learning, python

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/AIExL/vav_rc2021
  - doi: 
  - swh: swh:1:dir:4d43ea96458cc573dd2b57208fae0b12f8da896f

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "Daniel S. Brown, Jordan Schneider, Anca D. Dragan, Scott Niekum. Value Alignment Verification (ICML 2021)."
 - bib:  brown2021value
 - url:  https://arxiv.org/pdf/2012.01557.pdf
 - doi:  # Regular digital object identifier

# Don't forget to surround abstract with double quotes
abstract: "Scope of Reproducibility: The main goal of the paper 'Value Alignment Verification' is to test the alignment of a robot's behavior efficiently with human expectations by constructing a minimal set of questions. To accomplish this, the authors propose algorithms and heuristics to create the above questionnaire. They choose a wide range of gridworld environments and a continuous autonomous driving domain to validate their put forth claims. We explore value alignment verification for gridworlds incorporating a non-linear feature reward mapping as well as an extended action space. 
Methodology: We re-implemented the pipeline with Python using mathematical libraries such as Numpy and Scipy. We spent approximately two months reproducing the targeted claims in the paper with the first month aimed at reproducing the results for algorithms and heuristics for exact value alignment verification. The second month focused on extending the action space, additional experiments, and refining the structure of our code. Since our experiments were not computationally expensive, we carried out the experiments on CPU. 
Results: The techniques proposed by authors can successfully address the value alignment verification problem in different settings. We empirically demonstrate the effectiveness of their proposals by performing exhaustive experiments with several variations to their original claims. We show high accuracy and low false positive and false negative rates in the value alignment verification task with a minimum number of questions for different algorithms and heuristics.
What was easy: The problem statement, as well as the implementation of algorithms and heuristics, were straightforward. We also took aid from the original repository published with the paper. However, we implemented the entire pipeline from scratch and incorporated several variations to our code to perform additional designed experiments.
What was difficult: Comprehending different algorithms and heuristics proposed in prior works along with their mathematical formulation and reasoning for their success in the given task was considerably difficult. Additionally, the original code base had several redundant files, which created initial confusion. We iterated and discussed the arguments in the paper and prior work several times to thoroughly understand the pipeline. Nevertheless, once the basics were clear, the implementation was comparatively simple.
Communication with original authors: We reached out to the authors numerous times via email to seek clarifications and additional implementation details. The authors were incredibly receptive to our inquiries, and we appreciate their thorough and prompt responses."

# Bibliography file (yours)
bibliography: bibliography.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2021

# Coding language (main one only if several)
language: Python


# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=BFLM3nMmhCt

contributors:
  - name: Koustuv Sinha,\\ Sharath Chandra Raparthy
    orcid:
    role: editor
  - name: Anonymous Reviewers
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer


# This information will be provided by the editor
dates:
  - received:  February 4, 2022
  - accepted:  April 11, 2022
  - published:  May 23, 2022


# This information will be provided by the editor
article:
  - number: 31
  - doi: 10.5281/zenodo.6574687
  - url: https://zenodo.org/record/6574687/files/article.pdf

# This information will be provided by the editor
journal:
  - name:   "ReScience C"
  - issn:   2430-3658
  - volume: 8
  - issue: 2
