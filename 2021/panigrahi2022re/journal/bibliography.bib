@inproceedings{brown2021value,
  title={Value Alignment Verification},
  author={Brown, Daniel S and Schneider, Jordan and Dragan, Anca and Niekum, Scott},
  booktitle={International Conference on Machine Learning},
  pages={1105--1115},
  year={2021},
  organization={PMLR}
}
@inproceedings{huang2018establishing,
  title={Establishing appropriate trust via critical states},
  author={Huang, Sandy H and Bhatia, Kush and Abbeel, Pieter and Dragan, Anca D},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3929--3936},
  year={2018},
  organization={IEEE}
}
@article{hadfield2016cooperative,
  title={Cooperative inverse reinforcement learning},
  author={Hadfield-Menell, Dylan and Russell, Stuart J and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={3909--3917},
  year={2016}
}
@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul and Leike, Jan and Brown, Tom B and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={arXiv preprint arXiv:1706.03741},
  year={2017}
}
@article{sadigh2017active,
  title={Active preference-based learning of reward functions},
  author={Sadigh, Dorsa and Dragan, Anca D and Sastry, Shankar and Seshia, Sanjit A},
  year={2017}
}
@article{amin2017repeated,
  title={Repeated inverse reinforcement learning},
  author={Amin, Kareem and Jiang, Nan and Singh, Satinder},
  journal={arXiv preprint arXiv:1705.05427},
  year={2017}
}
@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}
@article{barreto2016successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and Van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1606.05312},
  year={2016}
}
@inproceedings{brown2020safe,
  title={Safe imitation learning via fast bayesian reward inference from preferences},
  author={Brown, Daniel and Coleman, Russell and Srinivasan, Ravi and Niekum, Scott},
  booktitle={International Conference on Machine Learning},
  pages={1165--1177},
  year={2020},
  organization={PMLR}
}
@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}
@article{russell2002artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart and Norvig, Peter},
  year={2002}
}
@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}
@inproceedings{brown2019machine,
  title={Machine teaching for inverse reinforcement learning: Algorithms and applications},
  author={Brown, Daniel S and Niekum, Scott},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={7749--7758},
  year={2019}
}
@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}
@article{russell2015research,
  title={Research priorities for robust and beneficial artificial intelligence},
  author={Russell, Stuart and Dewey, Daniel and Tegmark, Max},
  journal={Ai Magazine},
  volume={36},
  number={4},
  pages={105--114},
  year={2015}
}
@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}
@incollection{fisac2020pragmatic,
  title={Pragmatic-pedagogic value alignment},
  author={Fisac, Jaime F and Gates, Monica A and Hamrick, Jessica B and Liu, Chang and Hadfield-Menell, Dylan and Palaniappan, Malayandi and Malik, Dhruv and Sastry, S Shankar and Griffiths, Thomas L and Dragan, Anca D},
  booktitle={Robotics Research},
  pages={49--57},
  year={2020},
  publisher={Springer}
}
@article{shah2020benefits,
  title={Benefits of Assistance over Reward Learning},
  author={Shah, Rohin and Freire, Pedro and Alex, Neel and Freedman, Rachel and Krasheninnikov, Dmitrii and Chan, Lawrence and Dennis, Michael D and Abbeel, Pieter and Dragan, Anca and Russell, Stuart},
  year={2020}
}
@article{arora2021survey,
  title={A survey of inverse reinforcement learning: Challenges, methods and progress},
  author={Arora, Saurabh and Doshi, Prashant},
  journal={Artificial Intelligence},
  pages={103500},
  year={2021},
  publisher={Elsevier}
}
@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes and others},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={136},
  pages={1--46},
  year={2017},
  publisher={Journal of Machine Learning Research/Massachusetts Institute of Technology~â€¦}
}
@article{biyik2019asking,
  title={Asking easy questions: A user-friendly approach to active reward learning},
  author={B{\i}y{\i}k, Erdem and Palan, Malayandi and Landolfi, Nicholas C and Losey, Dylan P and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:1910.04365},
  year={2019}
}
@article{zhu2018overview,
  title={An overview of machine teaching},
  author={Zhu, Xiaojin and Singla, Adish and Zilles, Sandra and Rafferty, Anna N},
  journal={arXiv preprint arXiv:1801.05927},
  year={2018}
}
@inproceedings{cakmak2012algorithmic,
  title={Algorithmic and human teaching of sequential decision tasks},
  author={Cakmak, Maya and Lopes, Manuel},
  booktitle={Twenty-Sixth AAAI Conference on Artificial Intelligence},
  year={2012}
}
@article{huang2019enabling,
  title={Enabling robots to communicate their objectives},
  author={Huang, Sandy H and Held, David and Abbeel, Pieter and Dragan, Anca D},
  journal={Autonomous Robots},
  volume={43},
  number={2},
  pages={309--326},
  year={2019},
  publisher={Springer}
}
@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}
@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}
@inproceedings{thomas2015high,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}
@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}
@InProceedings{brown2019drex,
  title = {Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations},
  author = {Brown, Daniel S. and Goo, Wonjoon and Niekum, Scott},
  booktitle = {Proceedings of the 3rd Conference on Robot Learning},
  year = {2019}
}