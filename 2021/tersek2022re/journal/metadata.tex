% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/tersekmatija/re-LearningToCountEverything}
\def \codeDOI{10.5281/zenodo.6508260}
\def \codeSWH{swh:1:dir:cf19f5a717c777cd1097e938ef4e6bdb735f71c7}
\def \dataURL{https://drive.google.com/file/d/1ymDYrGs9DSRicfZbSCDiOu0ikGDh5k6S/view?usp=sharing}
\def \dataDOI{}
\def \editorNAME{Koustuv Sinha,\\ Sharath Chandra Raparthy}
\def \editorORCID{}
\def \reviewerINAME{Anonymous Reviewers}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{04 February 2022}
\def \dateACCEPTED{11 April 2022}
\def \datePUBLISHED{19 May 2022}
\def \articleTITLE{[Re] Learning to count everything}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2021}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2022}
\def \reviewURL{https://openreview.net/forum?id=HKbgd3zmh0t}
\def \articleABSTRACT{Scope of Reproducibility The core finding of the paper is a novel architecture FamNet for handling the few-shot counting task. We examine its implementation in the provided code on GitHub and compare it to the theory in the original paper. The authors also introduce a data set with 147 visual categories FSC-147, which we analyze. We try to reproduce the authors’ results on it and on CARPK data set. Additionally, we test FamNet on a category specific data set JHU-CROWD++. Furthermore, we try to reproduce the ground truth density maps, the code for which is not provided by the authors.
Methodology We use the combination of the authors’ and our own code, for parts where the code is not provided (e.g., generating ground truth density maps, CARPK data set preprocessing). We also modify some parts of the authors’ code so that we can evaluate the model on various data sets. For running the code we used the Quadro RTX 5000 GPU and had a total computation time of approximately 50 GPU hours.
Results We could not reproduce the density maps, but we produced similar density maps by modifying some of the parameters. We exactly reproduced the results on the paper’s data set. We did not get the same results on the CARPK data set and in experiments where implementation details were not provided. However, the differences are within standard error and our results support the claim that the model outperforms the baselines.
What was easy Running the pretrained models and the demo app was quite easy, as the authors provided instructions. It was also easy to reproduce the results on a given data set with a pretrained model.
What was difficult It was difficult to verify the ground truth density map generation as the code was not provided and the process was incorrectly described. Obtaining a performant GPU was also quite a challenge and it took quite many emails to finally get one. This also meant that we were unable to reproduce the training of the model.
Communication with original authors We contacted the authors three times through issues on GitHub. They were helpful and responsive, but we have not resolved all of the issues.}
\def \replicationCITE{Viresh Ranjan, Udbhav Sharma, Thu Nguyen, Minh Hoai. Learning To Count Everything (CVPR 2021).}
\def \replicationBIB{ranjan2021learning}
\def \replicationURL{https://arxiv.org/pdf/2104.08391.pdf}
\def \replicationDOI{10.48550/ARXIV.2104.08391}
\def \contactNAME{Domen Vreš}
\def \contactEMAIL{dv6968@student.uni-lj.si}
\def \articleKEYWORDS{few-shot learning, few-shot counting, CNN, counting data set, rescience c, machine learning, python}
\def \journalNAME{ReScience C}
\def \journalVOLUME{8}
\def \journalISSUE{2}
\def \articleNUMBER{39}
\def \articleDOI{10.0000/zenodo.0000000}
\def \authorsFULL{Maša Kljun, Matija Teršek and Domen Vreš}
\def \authorsABBRV{M. Kljun, M. Teršek and D. Vreš}
\def \authorsSHORT{Kljun, Teršek and Vreš}
\title{\articleTITLE}
\date{}
\author[1,2,\orcid{0000-0002-0893-8795}]{Maša Kljun}
\author[1,2,\orcid{0000-0002-3743-4895}]{Matija Teršek}
\author[1,2,\orcid{0000-0002-9225-2699}]{Domen Vreš}
\affil[1]{University of Ljubljana, Faculty of Computer and Information Science, Večna pot 113, 1000 Ljubljana}
\affil[2]{Equal contributions}
