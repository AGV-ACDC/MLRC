# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[Re] Explaining in Style: Training a GAN to explain a classifier in StyleSpace"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Noah van der Vleuten
    orcid: 0000-0002-7600-5428
    email: noahvdvleuten@gmail.com
    affiliations: 1,*

  - name: Tadija Radusinović
    orcid: 0000-0003-1670-9412
    email: tadija.radusinovic@student.uva.nl
    affiliations: 1      # * is for contact author

  - name: Rick Akkerman
    orcid: 0000-0003-4212-0724
    email: rick.akkerman@student.uva.nl
    affiliations: 1      # * is for contact author

  - name: Meilina Reksoprodjo
    orcid: 0000-0003-4445-4074
    email: m.reksoprodjo@student.tue.nl
    affiliations: 2      # * is for contact author

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    University of Amsterdam
    address: Amsterdam, The Netherlands
  - code:    2
    name:    Eindhoven University of Technology
    address: Eindhoven, The Netherlands


# List of keywords (adding the programming language might be a good idea)
keywords:  rescience c, machine learning, deep learning, python, pytorch, explainable ai, xai, gan, stylegan2, stylex

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/NoahVl/Explaining-In-Style-Reproducibility-Study
  - doi: 10.5281/zenodo.6512392
  - swh: swh:1:dir:04e11a55f476b115b40fd6af9d06ed70eb248535

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "Oran Lang, Yossi Gandelsman, Michal Yarom, Yoav Wald, Gal Elidan, Avinatan Hassidim, William T. Freeman,
 Phillip Isola, Amir Globerson, Michal Irani, Inbar Mosseri. Explaining in Style:
 Training a GAN To Explain a Classifier in StyleSpace (ICCV 2021)."
 - bib:  explaining_in_style
 - url:  https://arxiv.org/abs/2104.13369
 - doi:  10.48550/arXiv.2104.13369

# Don't forget to surround abstract with double quotes
abstract: "StylEx is a novel approach for classifier-conditioned training of StyleGan2, intending to capture classifier-specific attributes in its disentangled StyleSpace. Using the StylEx method, the behavior of a classifier can be explained and visualized by producing counterfactual images. The original authors, Lang et al., claim that its explanations are human-interpretable, distinct, coherent and sufficient to flip classifier predictions. Our replication efforts are five-fold: 1) As the training procedure and code were missing, we reimplemented the StylEx method in PyTorch to enable from the ground up reproducibility efforts of the original results. 2) We trained custom models on three datasets with a reduced image dimensionality to verify the original author’s claims. 3) We evaluate the Fréchet Inception Distance (FID) scores of generated images and show that the FID scores increase with the number of attributes used to generate a counterfactual explanation. 4) We conduct a user study (n=54) to evaluate the distinctiveness and coherence of the images, additionally we evaluate the ‘sufficiency’ scores of our models. 5) We release additional details on the training procedure of StylEx. Our experimental results support the claims posed in the original paper - the attributes detected by StylEx are identifiable by humans to a certain degree, distinct and sufficient. However, due to the significantly lower resolution and poorer image quality of the models, these results are not directly comparable to the ones posed in the original paper."

# Bibliography file (yours)
bibliography: bibliography.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2021

# Coding language (main one only if several)
language: Python


# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=SYUxyazQh0Y

contributors:
  - name:
    orcid:
    role: editor
  - name:
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer


# This information will be provided by the editor
dates:
  - received:
  - accepted:
  - published:


# This information will be provided by the editor
article:
  - number:
  - doi:
  - url:

# This information will be provided by the editor
journal:
  - name:
  - issn:
  - volume:
  - issue:
