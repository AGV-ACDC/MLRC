% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/NoahVl/Explaining-In-Style-Reproducibility-Study}
\def \codeDOI{10.5281/zenodo.6512392}
\def \codeSWH{swh:1:dir:04e11a55f476b115b40fd6af9d06ed70eb248535}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{Koustuv Sinha,\\ Sharath Chandra Raparthy}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{04 February 2022}
\def \dateACCEPTED{11 April 2022}
\def \datePUBLISHED{19 May 2022}
\def \articleTITLE{[Re] Explaining in Style: Training a GAN to explain a classifier in StyleSpace}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2021}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2022}
\def \reviewURL{https://openreview.net/forum?id=SYUxyazQh0Y}
\def \articleABSTRACT{StylEx is a novel approach for classifier-conditioned training of StyleGan2, intending to capture classifier-specific attributes in its disentangled StyleSpace. Using the StylEx method, the behavior of a classifier can be explained and visualized by producing counterfactual images. The original authors, Lang et al., claim that its explanations are human-interpretable, distinct, coherent and sufficient to flip classifier predictions. Our replication efforts are five-fold: 1) As the training procedure and code were missing, we reimplemented the StylEx method in PyTorch to enable from the ground up reproducibility efforts of the original results. 2) We trained custom models on three datasets with a reduced image dimensionality to verify the original author’s claims. 3) We evaluate the Fréchet Inception Distance (FID) scores of generated images and show that the FID scores increase with the number of attributes used to generate a counterfactual explanation. 4) We conduct a user study (n=54) to evaluate the distinctiveness and coherence of the images, additionally we evaluate the ‘sufficiency’ scores of our models. 5) We release additional details on the training procedure of StylEx. Our experimental results support the claims posed in the original paper - the attributes detected by StylEx are identifiable by humans to a certain degree, distinct and sufficient. However, due to the significantly lower resolution and poorer image quality of the models, these results are not directly comparable to the ones posed in the original paper.}
\def \replicationCITE{Oran Lang, Yossi Gandelsman, Michal Yarom, Yoav Wald, Gal Elidan, Avinatan Hassidim, William T. Freeman, Phillip Isola, Amir Globerson, Michal Irani, Inbar Mosseri. Explaining in Style: Training a GAN To Explain a Classifier in StyleSpace (ICCV 2021).}
\def \replicationBIB{explaining_in_style}
\def \replicationURL{https://arxiv.org/abs/2104.13369}
\def \replicationDOI{10.48550/arXiv.2104.13369}
\def \contactNAME{Noah van der Vleuten}
\def \contactEMAIL{noahvdvleuten@gmail.com}
\def \articleKEYWORDS{rescience c, machine learning, deep learning, python, pytorch, explainable ai, xai, gan, stylegan2, stylex}
\def \journalNAME{None}
\def \journalVOLUME{8}
\def \journalISSUE{2}
\def \articleNUMBER{42}
\def \articleDOI{}
\def \authorsFULL{Noah van der Vleuten et al.}
\def \authorsABBRV{N.V.D. Vleuten et al.}
\def \authorsSHORT{Vleuten et al.}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0000-0002-7600-5428}]{Noah van der Vleuten}
\author[1,\orcid{0000-0003-1670-9412}]{Tadija Radusinović}
\author[1,\orcid{0000-0003-4212-0724}]{Rick Akkerman}
\author[2,\orcid{0000-0003-4445-4074}]{Meilina Reksoprodjo}
\affil[1]{University of Amsterdam, Amsterdam, The Netherlands}
\affil[2]{Eindhoven University of Technology, Eindhoven, The Netherlands}
